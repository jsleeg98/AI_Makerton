{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê²°ê³¼ ì½”ë“œ ì‹¤í–‰ ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í˜„ì¬ ìœ„ì¹˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/twopiece/src/yolov5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. yolov5ë¡œ ìœ„ì¹˜ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twopiece/src/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. val.py ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì œì¶œ txt íŒŒì¼ ë§Œë“¤ê¸°\n",
    "* yolov5/runs/val/labelsì— txt íŒŒì¼ì´ ì €ì¥ëœë‹¤.\n",
    "* --dataì— yaml íŒŒì¼ì„ ì„¤ì •í•˜ë©´ ëœë‹¤.\n",
    "* ì‹¤í–‰í•˜ë©´ yolov5/runs/val/ì— resultë¡œ ê²°ê³¼ê°€ ì¶œë ¥ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/twopiece/datasets_rw/final-dataset/data.yaml, weights=yolov5x_trained_best.pt, batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=runs/val, name=result , exist_ok=False, half=False\n",
      "YOLOv5 ğŸš€ v5.0-507-g4cf7d48 torch 1.7.1+cu110 CUDA:0 (A100-SXM4-40GB MIG 2g.10gb, 9984.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87205423 parameters, 0 gradients, 217.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/twopiece/datasets_rw/final-dataset/val.cache' images and la\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        977       2972      0.995      0.987      0.995       0.86\n",
      "              helmat        977       1930      0.996      0.989      0.995      0.874\n",
      "                head        977       1042      0.993      0.985      0.995      0.846\n",
      "Speed: 0.1ms pre-process, 23.1ms inference, 1.5ms NMS per image at shape (32, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/val/result \u001b[0m\n",
      "977 labels saved to runs/val/result /labels\n"
     ]
    }
   ],
   "source": [
    "!python val.py --data /home/twopiece/datasets_rw/final-dataset/data.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
